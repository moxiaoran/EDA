---
title: "ramen_ratings"
author: "Yifei Liu"
date: "6/23/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dplyr)
library(skimr)
library(Matrix)
library(lubridate)
library(rvest)
library(drlib)
library(tigris)
library(doMC)
registerDoMC(cores = 4)
library(widyr)
library(glmnet)
library(spData)
library(sf)
library(scales)
library(broom)
library(tidytext)
library(ggraph)
library(igraph)
theme_set(theme_minimal())

ramen_ratings <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv") %>%
  select(-review_number) %>%
  mutate(country = case_when(country == "USA" ~ "United States",
                             T ~ country)) %>%
  filter(!is.na(stars)) %>%
  mutate(ramen_id = row_number())

world <- spData::world

```
Let's take a look at dataset. See how many missing data do we have. 

```{r}
skim(ramen_ratings)

ramen_ratings %>%
  filter(is.na(stars))

ramen_ratings

ramen_ratings_processed <- ramen_ratings %>%
  mutate(style = fct_lump(style, 4),
         country = fct_lump(country, 12),
         brand = fct_lump(brand, 20)) %>%
  replace_na(list(style = "Other")) %>%
  mutate(brand = fct_relevel(brand, "Other"),
         country = fct_relevel(country, "Other"),
         style = fct_relevel(style, "Other")) 
  

```

we have several missing rating and 2 missing in styples. Which means our dataset is pretty complete. 

We can ask several questions such as which country produce most Ramen, which brand produce most ramen. 


```{r}
ramen_ratings %>%
  mutate(style = fct_lump(style, 4),
         country = fct_lump(country, 12),
         brand = fct_lump(brand, 9)) %>%
  gather(category, value, -ramen_id, -stars, -variety) %>%
  count(category, value) %>%
  group_by(category) %>%
  top_n(20, n) %>%
  ungroup() %>%
  mutate(value = reorder_within(value, n, category)) %>%
  ggplot(aes(value, n)) +
  geom_col() +
  facet_wrap(~ category, scales = "free_y") +
  scale_x_reordered() +
  coord_flip() +
  labs(x = "Predictor",
       y = "Count",
       title = "Categorical predictors(after processing)")

```

we can see this data review most ramen from Japna, US, SK, Taiwan, China. Most common brand is Nissin, Nongshim Maruchan. Most common style is Pack Bolw Cup and Tray. 


```{r}
ramen_ratings %>%
  filter(!is.na(stars)) %>%
  mutate(country = fct_lump(country, 9),
         country = fct_reorder(country, stars)) %>%
  ggplot(aes(country, stars, color = country, fill = country)) +
  geom_boxplot(show.legend = F, alpha = 0.2) +
  coord_flip() +
  labs(x = "", y = "Ramen Ratings",
       title = "Which country Ramen have the highest ratings",
       subtitle = "Method is median",
       caption = "Data: The Ramen Raters")

  

```

we can see which country have the Highest Ramen rating, it surpris me that Malaysia ramen have the highest ratings. 



Let's try to build regression model see which factor explain ramen ratings the best. 

```{r}
model <- ramen_ratings %>%
    replace_na(list(style = "Missing")) %>%
    mutate(country = fct_lump(country, 9),
           country = fct_relevel(country, "Other"), 
           style = fct_lump(style, 4),
           style = fct_relevel(style, "Pack"), 
           brand = fct_lump(brand, 10),
           brand = fct_relevel(brand, "Other"), ) %>%
  lm(stars ~ country + style + brand, data = .)
   
model %>%
  tidy(conf.int = T) %>%
  filter(term != "(Intercept)") %>%
  tidyr::extract(term, c("category", "term"), "^([a-z]+)([A-Z].*)") %>%
  mutate(term = fct_reorder(term, estimate)) %>%
  ggplot(aes(estimate, term, color = category)) +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), show.legend = F) +
  geom_point(size = 3, show.legend = F) +
  facet_wrap(~ category, ncol = 1, scales = "free_y") +
  geom_vline(lty = 2, xintercept = 0) +
  labs(x = "",
       y = "",
       title = "Coefficient that predict Ramen ratings.",
       subtitle = "Less common brand, countries were used as the reference level. Pack were used as the reference level in Style")

anova(model) %>%
  tidy() %>%
  mutate(sumsq / sum(sumsq))

```


```{r}
model %>%
  augment(date = ramen_ratings) %>%
  ggplot(aes(.fitted, stars)) +
  geom_point(alpha = 0.1)
```

we can say country, style and brand fail to explain the ratings. we may need more variabel such as price to determine the ramen ratings. 

Now take a look at Ramen Variety see which country associate with high quality. 

```{r}
ratings_variety <- ramen_ratings %>%
  select(ramen_id, style, variety, stars)

ratings_words <- ratings_variety %>%
  unnest_tokens(word, variety) %>%
  anti_join(stop_words, by = "word") %>%
  filter(str_detect(word, "[a-z]"),
         !str_detect(word, "[0-9]"),
         !word %in% c("noodles", "noodle","instant", "ramen", "flavour", "flavor"))



# top 10 word appear in variety

ratings_words %>%
  count(word, sort = T) %>%
  head(10) %>%
  mutate(word = fct_reorder(word, n)) %>%
  ggplot(aes(word, n, fill = word)) +
  geom_col(show.legend = F) +
  coord_flip() +
  labs(x = "",
       y = "",
       title = "Most common words in ramen variety")
  

```

### lasso regression on words in description. 



```{r}
# counting and pairing words

ratings_words %>%
  count(word, sort = T)

ramen_word_filtered <- ratings_words %>%
  group_by(word) %>%
  filter(n() >= 33)


ramen_word_filtered %>%
  pairwise_cor(word, ramen_id, sort = T)

```


```{r}
ramen_word_matrix <- ramen_word_filtered %>%
  cast_sparse(ramen_id, word)

ramen_id <- as.integer(rownames(ramen_word_matrix)) 
ramen_stars <- ramen_ratings$stars[ramen_id] 

cv_glmnet_model <- cv.glmnet(ramen_word_matrix, ramen_stars, parallel = T)

plot(cv_glmnet_model)

```

when we include 103 describe words, model start overfitting at 64 words. so we can decrease the word to 64

```{r}
lexicon <- cv_glmnet_model$glmnet.fit %>%
  tidy() %>%
  filter(lambda == cv_glmnet_model$lambda.1se,
         term != "(Intercept)",
         term != "log_price")


lexicon %>%
  arrange(estimate) %>%
  group_by(direction = ifelse(estimate > 0, "Positive", "Negative")) %>%
  top_n(10, abs(estimate)) %>%
  ungroup() %>%
  mutate(term = fct_reorder(term, estimate)) %>%
  ggplot(aes(term, estimate, fill = direction)) +
  geom_col() +
  coord_flip() +
  labs(x = "",
       y = "",
       title = "Which word is predictive in Ramen ratings")

```


```{r}
ratings_words %>%
  filter(ramen_id %in% sample(unique(ramen_id), 6)) %>%
  distinct(word, ramen_id, stars) %>%
  select(word, ramen_id, stars) %>%
  inner_join(lexicon, by = c("word" = "term"))


```



### Web Scrappings

```{r}
ramen_list <- read_html("https://www.theramenrater.com/resources-2/the-list/")

# how the original data been scriptted. 

ramen_review <- ramen_list %>%
  html_node("#myTable") %>%
  html_table() %>%
  tbl_df() %>%
  janitor::clean_names() %>%
  select(-t)

```



```{r}
review_links <- read_html("https://www.theramenrater.com/resources-2/the-list/") %>%
  html_nodes("#myTable a")

reviews <- tibble(review_numbers = parse_number(html_text(review_links)),
                 link = html_attr(review_links, "href"))

```

See here for more about possible and other "Dealing with failure" functions: 


```{r}
get_review_text <- function(url) {
  message(url)
  
 read_html(url) %>%
  html_nodes(".entry-content > p") %>%
  html_text() %>%
  str_subset(".")
}

reviews_text <- reviews %>%
  head(250) %>%
  mutate(text = purrr::map(link, possibly(get_review_text, character(0), quiet = F)))
```


```{r}

review_paragraphs <- reviews_text %>%
  filter(!map_lgl(text, is.null)) %>%
  unnest() %>%
  filter(str_detect(text, "Finished")) %>%
  mutate(text = str_remove(text, "Finished .*?\\. "))

review_tokenized <- review_paragraphs %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, "word") %>%
  filter(str_detect(word, "[a-z]")) %>%
  inner_join(ramen_ratings, by = c("review_numbers" = "ramen_id"))
  

review_words <- review_tokenized %>%
  group_by(word) %>%
  summarize(nuber = n(),
            reviews = n_distinct(review_numbers),
            avg_rating = mean(stars)) %>%
  arrange(desc(reviews))

reivew_words_filtered <- review_words %>%
  filter(reviews < 200, reviews >= 10)


words_cor <- review_tokenized %>%
  semi_join(reivew_words_filtered, by = "word") %>%
  distinct(review_numbers, word) %>%
  pairwise_cor(word, review_numbers, sort = T)


```

More on correlation graphic: https://www.tidytextmining.com/ngrams.html


```{r}

filtered_cors <- words_cor %>%
  head(200)

nodes <- reivew_words_filtered %>%
  filter(word %in% filtered_cors$item1 |
         word %in% filtered_cors$item2)

filtered_cors %>%
  graph_from_data_frame(vertices = nodes) %>%
  ggraph() +
  geom_edge_link() +
  geom_node_point(aes(size = reviews * 1.1)) +
  geom_node_point(aes(size = reviews, color = avg_rating)) +
  geom_node_text(aes(label = name), repel = TRUE) + 
  scale_color_gradient2(low = "red", high = "blue", midpoint = 3) +
  theme_void() +
  labs(color = "Average Rating",
       size = "# of reviews",
       title = "Network of words used together in Ramen reviews", 
       subtitle = "Based on 250 ramen reviews and their star ratings")

```






















